{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a13f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021c54b",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eef1b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[23]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>9.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[25]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[26]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[27]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[28]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[34]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[35]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[36]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Dame Tu Cosita\"[38]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sorry\"[40]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[43]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Wheels on the Bus\"[44]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Axel F\"[52]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Mi Gente\"[53]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Perfect\"[54]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[55]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Hello\"[56]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"[23]   \n",
       "1    2.                                  \"Despacito\"[25]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[26]   \n",
       "3    4.                               \"Shape of You\"[27]   \n",
       "4    5.                              \"See You Again\"[28]   \n",
       "5    6.                                  \"Bath Song\"[31]   \n",
       "6    7.  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "7    8.   \"Masha and the Bear – Recipe for Disaster\"[33]   \n",
       "8    9.                                \"Uptown Funk\"[34]   \n",
       "9   10.                \"Phonics Song with Two Words\"[35]   \n",
       "10  11.                              \"Gangnam Style\"[36]   \n",
       "11  12.                             \"Dame Tu Cosita\"[38]   \n",
       "12  13.                                      \"Sugar\"[39]   \n",
       "13  14.                                      \"Sorry\"[40]   \n",
       "14  15.                                       \"Roar\"[41]   \n",
       "15  16.                             \"Counting Stars\"[42]   \n",
       "16  17.                          \"Thinking Out Loud\"[43]   \n",
       "17  18.                          \"Wheels on the Bus\"[44]   \n",
       "18  19.                                      \"Faded\"[45]   \n",
       "19  20.                                 \"Dark Horse\"[46]   \n",
       "20  21.                             \"Girls Like You\"[47]   \n",
       "21  22.                                    \"Lean On\"[48]   \n",
       "22  23.                                   \"Bailando\"[49]   \n",
       "23  24.                               \"Shake It Off\"[50]   \n",
       "24  25.                                 \"Let Her Go\"[51]   \n",
       "25  26.                                     \"Axel F\"[52]   \n",
       "26  27.                                   \"Mi Gente\"[53]   \n",
       "27  28.                                    \"Perfect\"[54]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[55]   \n",
       "29  30.                                      \"Hello\"[56]   \n",
       "\n",
       "                                         Artist        Upload_date Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  9.53  \n",
       "1                                    Luis Fonsi   January 12, 2017  7.59  \n",
       "2                                   LooLoo Kids    October 8, 2016  5.82  \n",
       "3                                    Ed Sheeran   January 30, 2017  5.50  \n",
       "4                                   Wiz Khalifa      April 6, 2015  5.30  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018  4.57  \n",
       "6                                   Miroshka TV  February 27, 2018  4.52  \n",
       "7                                    Get Movies   January 31, 2012  4.46  \n",
       "8                                   Mark Ronson  November 19, 2014  4.34  \n",
       "9                                     ChuChu TV      March 6, 2014  4.25  \n",
       "10                                          Psy      July 15, 2012  4.23  \n",
       "11                                    El Chombo      April 5, 2018  3.66  \n",
       "12                                     Maroon 5   January 14, 2015  3.57  \n",
       "13                                Justin Bieber   October 22, 2015  3.48  \n",
       "14                                   Katy Perry  September 5, 2013  3.45  \n",
       "15                                  OneRepublic       May 31, 2013  3.42  \n",
       "16                                   Ed Sheeran    October 7, 2014  3.34  \n",
       "17                   Cocomelon – Nursery Rhymes       May 24, 2018  3.31  \n",
       "18                                  Alan Walker   December 3, 2015  3.16  \n",
       "19                                   Katy Perry  February 20, 2014  3.16  \n",
       "20                                     Maroon 5       May 31, 2018  3.15  \n",
       "21                                  Major Lazer     March 22, 2015  3.11  \n",
       "22                             Enrique Iglesias     April 11, 2014  3.11  \n",
       "23                                 Taylor Swift    August 18, 2014  3.11  \n",
       "24                                    Passenger      July 25, 2012  3.10  \n",
       "25                                   Crazy Frog      June 16, 2009  3.06  \n",
       "26                                     J Balvin      June 29, 2017  2.99  \n",
       "27                                   Ed Sheeran   November 9, 2017  2.99  \n",
       "28                                      Shakira       June 4, 2010  2.97  \n",
       "29                                        Adele   October 22, 2015  2.90  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\")\n",
    "\n",
    "# inserting data as per the required job key:\n",
    "search = driver.find_element_by_xpath(\"//input[@class='vector-search-box-input']\")\n",
    "search.send_keys('List of most-viewed YouTube videos/ in Wikipedia ')\n",
    "\n",
    "# clicking on search:\n",
    "serch_btn = driver.find_element_by_xpath(\"//input[@id='searchButton']\").click()\n",
    "\n",
    "# clicking on search:\n",
    "click_ = driver.find_element_by_xpath(\"//div[@class = 'mw-search-result-heading']/a\").click()\n",
    "\n",
    "\n",
    "# empty lists\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_date = []\n",
    "Views = []\n",
    "\n",
    "\n",
    "# scraping rank of the song\n",
    "rank = driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    try:\n",
    "        Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append(\"-\")\n",
    "\n",
    "# scraping name of the song\n",
    "name = driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "\n",
    "# scraping the name of the artist\n",
    "artist= driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[3]\")\n",
    "for i in artist:\n",
    "    try:\n",
    "        Artist.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append('-')\n",
    "\n",
    "# scraping date of posting\n",
    "date= driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[5]\")\n",
    "for i in date:\n",
    "    try:\n",
    "        Upload_date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Upload_date.append('-')\n",
    "\n",
    "# scraping the number of views\n",
    "view= driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[4]\")\n",
    "for i in view:\n",
    "    try:\n",
    "        Views.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Views.append('-')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# creating dataframe:\n",
    "df = pd.DataFrame({})\n",
    "df['Rank'] = Rank\n",
    "df['Name'] = Name\n",
    "df['Artist'] = Artist\n",
    "df['Upload_date'] = Upload_date\n",
    "df['Views'] = Views\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d9f79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884112cf",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b352004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "# clicking on search:\n",
    "international = driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\").click()\n",
    "fixtures = driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321410bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_in= driver.find_element_by_xpath(\"//*[@id='TestAlexFilter']\").click()\n",
    "odi= driver.find_element_by_xpath(\"//*[@id='TestAlexFilter']/div/ul/li[4]/span\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d620a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_22 = driver.find_element_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a[1]\").click()\n",
    "view = driver.find_element_by_xpath(\"/html/body/div[2]/div/header/div/div[1]/div/p/a\").click()\n",
    "fix = driver.find_element_by_xpath('/html/body/div[4]/div/div/div[1]/div/nav/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc7d5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ST ODI</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>Sunday 6 February</td>\n",
       "      <td>1:00pm IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ND ODI</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>Sawai Mansingh Stadium, Jaipur</td>\n",
       "      <td>Wednesday 9 February</td>\n",
       "      <td>1:00pm IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3RD ODI</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>Saturday 12 February</td>\n",
       "      <td>1:00pm IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ST T20I</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>Barabati Stadium, Cuttack</td>\n",
       "      <td>Tuesday 15 February</td>\n",
       "      <td>7:00pm IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ND T20I</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>ACA-VDCA Stadium, Visakhapatnam</td>\n",
       "      <td>Friday 18 February</td>\n",
       "      <td>7:00pm IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3RD T20I</td>\n",
       "      <td>India v West Indies 2022</td>\n",
       "      <td>Greenfield Stadium, Thiruvananthapuram</td>\n",
       "      <td>Sunday 20 February</td>\n",
       "      <td>7:00pm IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_title                    Series  \\\n",
       "0     1ST ODI  India v West Indies 2022   \n",
       "1     2ND ODI  India v West Indies 2022   \n",
       "2     3RD ODI  India v West Indies 2022   \n",
       "3    1ST T20I  India v West Indies 2022   \n",
       "4    2ND T20I  India v West Indies 2022   \n",
       "5    3RD T20I  India v West Indies 2022   \n",
       "\n",
       "                                    Place                  Date        Time  \n",
       "0        Narendra Modi Stadium, Ahmedabad     Sunday 6 February  1:00pm IST  \n",
       "1          Sawai Mansingh Stadium, Jaipur  Wednesday 9 February  1:00pm IST  \n",
       "2                   Eden Gardens, Kolkata  Saturday 12 February  1:00pm IST  \n",
       "3               Barabati Stadium, Cuttack   Tuesday 15 February  7:00pm IST  \n",
       "4         ACA-VDCA Stadium, Visakhapatnam    Friday 18 February  7:00pm IST  \n",
       "5  Greenfield Stadium, Thiruvananthapuram    Sunday 20 February  7:00pm IST  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty lists\n",
    "Match_title = []\n",
    "Place = []\n",
    "Series = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "        \n",
    "# scraping necessary links        \n",
    "href = []\n",
    "lnks1=driver.find_elements_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a\")\n",
    "for lnk in lnks1:\n",
    "    href.append(lnk.get_attribute('href'))\n",
    "    \n",
    "# scraping the data\n",
    "for i in href:\n",
    "    driver.get(i)\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    try:\n",
    "        title = driver.find_element_by_xpath(\"/html/body/div[2]/div/header/div/div[1]/div/p/span\")\n",
    "        Match_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Match_title.append('NaN')\n",
    "        \n",
    "    try:\n",
    "        series = driver.find_element_by_xpath(\"//*[@id='scorecard']/section[3]/div/ul/li[1]/span[2]\")\n",
    "        Series.append(series.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('NaN')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        date = driver.find_element_by_xpath(\"/html/body/div[2]/div/header/div/div[2]/div/div[4]/strong\")\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('NaN')\n",
    "        \n",
    "    try:\n",
    "        place = driver.find_element_by_xpath(\"//*[@id='scorecard']/section[3]/div/ul/li[3]/span[2]\")\n",
    "        Place.append(place.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('NaN')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        time = driver.find_element_by_xpath(\"/html/body/div[2]/div/header/div/div[2]/div/div[1]/span\")\n",
    "        Time.append(time.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('NaN')\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " # creating dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Match_title'] = Match_title\n",
    "df['Series'] = Series\n",
    "df['Place'] = Place\n",
    "df['Date'] = Date\n",
    "df['Time'] = Time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29fb46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a94340",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ebd1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can’t be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "click1 = driver.find_element_by_xpath(\"//*[@id='main-header']/div/div/div/div/div/div/div/div[2]/div[2]/div/button\").click()\n",
    "\n",
    "# inserting data as per the required job key:\n",
    "search = driver.find_element_by_xpath(\"//*[@id='search-drawer']/div[2]/div[2]/form/label/input\")\n",
    "search.send_keys('selenium exception handling')\n",
    "click_ = driver.find_element_by_xpath(\"//*[@id='search-drawer']/div[2]/div[2]/form/input\").click()\n",
    "\n",
    "# click on the desired link\n",
    "link = driver.find_element_by_xpath(\"//*[@id='___gcse_0']/div/div/div/div[5]/div[2]/div/div/div[1]/div[1]/div[1]/div[1]/div/a\").click()\n",
    "\n",
    "\n",
    "# empty lists\n",
    "Name = []\n",
    "Description = []\n",
    "\n",
    "\n",
    "name = driver.find_elements_by_xpath(\"//*[@id='post-1953']/div/div/table/tbody/tr/td[1]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('NaN')\n",
    "    \n",
    "\n",
    "desc = driver.find_elements_by_xpath(\"//*[@id='post-1953']/div/div/table/tbody/tr/td[2]\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        Description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NaN')\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame({})\n",
    "df['Name'] = Name\n",
    "df['Description'] = Description\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "323c0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccf7e0",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc67c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "\n",
    "eco = driver.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/button\").click()\n",
    "india = driver.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/div/a[3]\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e711dd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "5     6                West Bengal                     1,253,832   \n",
       "6     7                  Rajasthan                     1,020,989   \n",
       "7     8             Andhra Pradesh                       972,782   \n",
       "8     9                  Telangana                       969,604   \n",
       "9    10             Madhya Pradesh                       906,672   \n",
       "10   11                     Kerala                             -   \n",
       "11   12                      Delhi                       856,112   \n",
       "12   13                    Haryana                       831,610   \n",
       "13   14                      Bihar                       611,804   \n",
       "14   15                     Punjab                       574,760   \n",
       "15   16                     Odisha                       521,275   \n",
       "16   17                      Assam                             -   \n",
       "17   18               Chhattisgarh                       329,180   \n",
       "18   19                  Jharkhand                       328,598   \n",
       "19   20                Uttarakhand                             -   \n",
       "20   21            Jammu & Kashmir                             -   \n",
       "21   22           Himachal Pradesh                       165,472   \n",
       "22   23                        Goa                        80,449   \n",
       "23   24                    Tripura                        55,984   \n",
       "24   25                 Chandigarh                             -   \n",
       "25   26                 Puducherry                        38,253   \n",
       "26   27                  Meghalaya                        36,572   \n",
       "27   28                     Sikkim                        32,496   \n",
       "28   29                    Manipur                        31,790   \n",
       "29   30                   Nagaland                             -   \n",
       "30   31          Arunachal Pradesh                             -   \n",
       "31   32                    Mizoram                        26,503   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share(18-19) GDP($ billion)  \n",
       "0                      2,632,792       13.94%        399.921  \n",
       "1                      1,630,208        8.63%        247.629  \n",
       "2                      1,584,764        8.39%        240.726  \n",
       "3                      1,502,899        7.96%        228.290  \n",
       "4                      1,493,127        7.91%        226.806  \n",
       "5                      1,089,898        5.77%        165.556  \n",
       "6                        942,586        4.99%        143.179  \n",
       "7                        862,957        4.57%        131.083  \n",
       "8                        861,031        4.56%        130.791  \n",
       "9                        809,592        4.29%        122.977  \n",
       "10                       781,653        4.14%        118.733  \n",
       "11                       774,870        4.10%        117.703  \n",
       "12                       734,163        3.89%        111.519  \n",
       "13                       530,363        2.81%         80.562  \n",
       "14                       526,376        2.79%         79.957  \n",
       "15                       487,805        2.58%         74.098  \n",
       "16                       315,881        1.67%         47.982  \n",
       "17                       304,063        1.61%         46.187  \n",
       "18                       297,204        1.57%         45.145  \n",
       "19                       245,895        1.30%         37.351  \n",
       "20                       155,956        0.83%         23.690  \n",
       "21                       153,845        0.81%         23.369  \n",
       "22                        73,170        0.39%         11.115  \n",
       "23                        49,845        0.26%          7.571  \n",
       "24                        42,114        0.22%          6.397  \n",
       "25                        34,433        0.18%          5.230  \n",
       "26                        33,481        0.18%          5.086  \n",
       "27                        28,723        0.15%          4.363  \n",
       "28                        27,870        0.15%          4.233  \n",
       "29                        27,283        0.14%          4.144  \n",
       "30                        24,603        0.13%          3.737  \n",
       "31                        22,287        0.12%          3.385  \n",
       "32                             -            -              -  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#click on the link\n",
    "click1 = driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "\n",
    "\n",
    "# empty lists\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_19_20 = []\n",
    "GSDP18_19 = []\n",
    "Share18_19 = []\n",
    "GDP_billion = []\n",
    "\n",
    "# scraping rank\n",
    "rank = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    try:\n",
    "        Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append('NaN')\n",
    "\n",
    "# scraping state\n",
    "state = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    try:\n",
    "        State.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        State.append('NaN')\n",
    "        \n",
    "# scraping GSDP_19_20 \n",
    "gsdp1 = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[3]\")\n",
    "for i in gsdp1:\n",
    "    try:\n",
    "        GSDP_19_20.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP_19_20.append('NaN')\n",
    "        \n",
    "# scraping GSDP_18_19\n",
    "gsdp2 = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in gsdp2:\n",
    "    try:\n",
    "        GSDP18_19.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP18_19.append('NaN')\n",
    "        \n",
    "# scraping Share18_19\n",
    "share = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in share:\n",
    "    try:\n",
    "        Share18_19.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Share18_19.append('NaN')\n",
    "        \n",
    "# scraping GDP_billion\n",
    "gdp = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    try:\n",
    "        GDP_billion.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GDP_billion.append('NaN')\n",
    "        \n",
    "        \n",
    "# creating dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Rank'] = Rank\n",
    "df['State'] = State\n",
    "df['GSDP at current price (19-20)'] = GSDP_19_20\n",
    "df['GSDP at current price (18-19)'] = GSDP18_19\n",
    "df['Share(18-19)'] = Share18_19\n",
    "df['GDP($ billion)'] = GDP_billion\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "031bcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce91404",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984792fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4201d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on tab\n",
    "explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details\").click()\n",
    "trending = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01f01da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taichi-dev</td>\n",
       "      <td>Parallel programming for everyone.</td>\n",
       "      <td>110</td>\n",
       "      <td>C++,68.7%,Python,28.4%,C,1.0%,CMake,0.7%,Cuda,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WorkerLivesMatter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZhangNanBei 秃头才能变强,WorkerLivesMatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schollz</td>\n",
       "      <td>Easily and securely send things from one compu...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modern-js-dev</td>\n",
       "      <td>The meta-framework suite designed from scratch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edeng23</td>\n",
       "      <td>Automated cryptocurrency trading bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kubesphere</td>\n",
       "      <td>The container platform tailored for Kubernetes...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mli</td>\n",
       "      <td>深度学习经典、新论文逐段精读</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lihaoyun6</td>\n",
       "      <td>A VM launcher for Parallels Desktop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swift,83.6%,Shell,9.5%,Rich Text Format,6.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acidanthera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>denysvitali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>denysvitali Denys Vitali,stefanb Štefan Baeble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSPosed</td>\n",
       "      <td>Integrate Magisk root and OpenGApps into WSA (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>github</td>\n",
       "      <td>GitHub resources and information for the devel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>10 Weeks, 20 Lessons, Data Science for All!</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>251</td>\n",
       "      <td>C#,50.7%,C++,47.7%,Other,1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>swc-project</td>\n",
       "      <td>swc is a super-fast compiler written in rust; ...</td>\n",
       "      <td>1.5k</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vpncn</td>\n",
       "      <td>2021中国翻墙软件VPN推荐以及科学上网避坑，稳定好用。对比SSR机场、蓝灯、V2ray、...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arco-design</td>\n",
       "      <td>A comprehensive React UI components library</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>notifirehq</td>\n",
       "      <td>🚀 The open-source notification infrastructure ...</td>\n",
       "      <td>8</td>\n",
       "      <td>TypeScript,87.4%,Raku,5.8%,JavaScript,2.8%,Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tencent</td>\n",
       "      <td>✨ A Markdown Editor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lyngai,jiawei686,sunsonliu sunsonliu,humyfred ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OpenIMSDK</td>\n",
       "      <td>OpenIM：由前微信技术专家打造的基于 Go 实现的即时通讯（IM）项目，从服务端到客户端...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kon9chunkit</td>\n",
       "      <td>🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java,100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>waydabber</td>\n",
       "      <td>Software Dummy Display Adapter for Apple Silic...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>diem</td>\n",
       "      <td>Diem’s mission is to build a trusted and innov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>priyankavergadia</td>\n",
       "      <td>If you are looking to become a Google Cloud En...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>juicedata</td>\n",
       "      <td>JuiceFS is a distributed POSIX file system bui...</td>\n",
       "      <td>37</td>\n",
       "      <td>Go,81.1%,Java,16.2%,C,2.3%,Other,0.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Repository_title                             Repository_description  \\\n",
       "0          taichi-dev                 Parallel programming for everyone.   \n",
       "1   WorkerLivesMatter                                                NaN   \n",
       "2             schollz  Easily and securely send things from one compu...   \n",
       "3       modern-js-dev  The meta-framework suite designed from scratch...   \n",
       "4             edeng23               Automated cryptocurrency trading bot   \n",
       "5          kubesphere  The container platform tailored for Kubernetes...   \n",
       "6                 mli                                     深度学习经典、新论文逐段精读   \n",
       "7           lihaoyun6                A VM launcher for Parallels Desktop   \n",
       "8         acidanthera                                                NaN   \n",
       "9         denysvitali                                                NaN   \n",
       "10            LSPosed  Integrate Magisk root and OpenGApps into WSA (...   \n",
       "11             github  GitHub resources and information for the devel...   \n",
       "12          microsoft        10 Weeks, 20 Lessons, Data Science for All!   \n",
       "13          microsoft  Windows system utilities to maximize productivity   \n",
       "14        swc-project  swc is a super-fast compiler written in rust; ...   \n",
       "15              vpncn  2021中国翻墙软件VPN推荐以及科学上网避坑，稳定好用。对比SSR机场、蓝灯、V2ray、...   \n",
       "16        arco-design        A comprehensive React UI components library   \n",
       "17         notifirehq  🚀 The open-source notification infrastructure ...   \n",
       "18            Tencent                                ✨ A Markdown Editor   \n",
       "19          OpenIMSDK  OpenIM：由前微信技术专家打造的基于 Go 实现的即时通讯（IM）项目，从服务端到客户端...   \n",
       "20        kon9chunkit  🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...   \n",
       "21          waydabber  Software Dummy Display Adapter for Apple Silic...   \n",
       "22               diem  Diem’s mission is to build a trusted and innov...   \n",
       "23   priyankavergadia  If you are looking to become a Google Cloud En...   \n",
       "24          juicedata  JuiceFS is a distributed POSIX file system bui...   \n",
       "\n",
       "   Contributors_count                                      Language_used  \n",
       "0                 110  C++,68.7%,Python,28.4%,C,1.0%,CMake,0.7%,Cuda,...  \n",
       "1                 NaN               ZhangNanBei 秃头才能变强,WorkerLivesMatter  \n",
       "2                   4                                                     \n",
       "3                 NaN                                                     \n",
       "4                 NaN                                                     \n",
       "5                   2                                                     \n",
       "6                 NaN                                                NaN  \n",
       "7                 NaN       Swift,83.6%,Shell,9.5%,Rich Text Format,6.9%  \n",
       "8                 NaN                                                     \n",
       "9                 NaN  denysvitali Denys Vitali,stefanb Štefan Baeble...  \n",
       "10                NaN                                                NaN  \n",
       "11                NaN                                                NaN  \n",
       "12                NaN                                                     \n",
       "13                251                      C#,50.7%,C++,47.7%,Other,1.6%  \n",
       "14               1.5k                                                     \n",
       "15                NaN                                                NaN  \n",
       "16                  6                                                     \n",
       "17                  8  TypeScript,87.4%,Raku,5.8%,JavaScript,2.8%,Per...  \n",
       "18                NaN  lyngai,jiawei686,sunsonliu sunsonliu,humyfred ...  \n",
       "19                NaN                                                     \n",
       "20                NaN                                        Java,100.0%  \n",
       "21                                                                   NaN  \n",
       "22                NaN                                                     \n",
       "23                NaN                                                NaN  \n",
       "24                 37              Go,81.1%,Java,16.2%,C,2.3%,Other,0.4%  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#empty lists\n",
    "Repository_title = []\n",
    "Repository_description = []\n",
    "Contributors_count = []\n",
    "Language_used = []\n",
    "\n",
    "\n",
    "\n",
    "# scraping necessary links        \n",
    "href = []\n",
    "lnks1=driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/h1/a\")\n",
    "for lnk in lnks1:\n",
    "    href.append(lnk.get_attribute('href'))\n",
    "    \n",
    "# scraping the data    \n",
    "for i in href:\n",
    "    driver.get(i)\n",
    "    driver.implicitly_wait(10)\n",
    "    try:\n",
    "        title = driver.find_element_by_xpath(\"//*[@id='repository-container-header']/div[1]/div/h1/span[1]/a\")\n",
    "        Repository_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append(\"NaN\")\n",
    "        \n",
    "    try:\n",
    "        desc = driver.find_element_by_xpath(\"//*[@id='repo-content-pjax-container']/div/div[2]/div[2]/div/div[1]/div/p\")\n",
    "        Repository_description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append(\"NaN\")\n",
    "        \n",
    "    try:\n",
    "        count = driver.find_element_by_xpath(\"//*[@id='repo-content-pjax-container']/div/div[2]/div[2]/div/div[4]/div/h2/a/span\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append(\"NaN\")\n",
    "        \n",
    "\n",
    "    try:\n",
    "        lang = driver.find_element_by_xpath(\"//*[@id='repo-content-pjax-container']/div/div[2]/div[2]/div/div[5]/div/ul\")\n",
    "        Language_used.append(lang.text.replace('\\n',','))\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append(\"NaN\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# creating dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Repository_title'] = Repository_title\n",
    "df['Repository_description'] = Repository_description\n",
    "df['Contributors_count'] = Contributors_count\n",
    "df['Language_used'] = Language_used\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6042807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e028d",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46ecf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a894c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on tab\n",
    "hot_100 = driver.find_element_by_xpath(\"//*[@id='root']/div[2]/div[2]/nav/ul/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e987326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy On Me</td>\n",
       "      <td>Adele</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fancy Like</td>\n",
       "      <td>Walker Hayes</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad Habits</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Who's In Your Head</td>\n",
       "      <td>Jonas Brothers</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Woo Baby</td>\n",
       "      <td>Pop Smoke Featuring Chris Brown</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Flocky Flocky</td>\n",
       "      <td>Don Toliver Featuring Travis Scott</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Like A Lady</td>\n",
       "      <td>Lady A</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Just About Over You</td>\n",
       "      <td>Priscilla Block</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Song_name                         Artist_name Last_week_rank  \\\n",
       "0            Easy On Me                               Adele             68   \n",
       "1                  Stay       The Kid LAROI & Justin Bieber              1   \n",
       "2         Industry Baby             Lil Nas X & Jack Harlow              1   \n",
       "3            Fancy Like                        Walker Hayes              3   \n",
       "4            Bad Habits                          Ed Sheeran              2   \n",
       "..                  ...                                 ...            ...   \n",
       "95   Who's In Your Head                      Jonas Brothers             95   \n",
       "96             Woo Baby     Pop Smoke Featuring Chris Brown             64   \n",
       "97        Flocky Flocky  Don Toliver Featuring Travis Scott             53   \n",
       "98          Like A Lady                              Lady A             90   \n",
       "99  Just About Over You                     Priscilla Block             97   \n",
       "\n",
       "   Peak_rank Weeks_on_board  \n",
       "0          1              2  \n",
       "1         15             15  \n",
       "2         13             13  \n",
       "3         18             18  \n",
       "4         17             17  \n",
       "..       ...            ...  \n",
       "95         2              2  \n",
       "96         3              3  \n",
       "97         2              2  \n",
       "98         2              2  \n",
       "99         2              2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty lists\n",
    "Song_name = []\n",
    "Artist_name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []\n",
    "\n",
    "\n",
    "# scraping song name\n",
    "name = driver.find_elements_by_xpath(\"//*[@id='charts']/div/div/div/ol/li/button/span[2]/span[1]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Song_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Song_name.append('NaN')\n",
    "\n",
    "# scraping artist name\n",
    "art_name = driver.find_elements_by_xpath(\"//*[@id='charts']/div/div/div/ol/li/button/span[2]/span[2]\")\n",
    "for i in art_name:\n",
    "    try:\n",
    "        Artist_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist_name.append('NaN')\n",
    "        \n",
    "# scraping last week rank \n",
    "last_rank = driver.find_elements_by_xpath(\"//*[@id='charts']/div/div/div/ol/li/button/div/div[2]\")\n",
    "for i in last_rank:\n",
    "    try:\n",
    "        Last_week_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Last_week_rank.append('NaN')\n",
    "        \n",
    "# scraping peak rank\n",
    "p_rank = driver.find_elements_by_xpath(\"//*[@id='charts']/div/div/div/ol/li/button/div/div[3]\")\n",
    "for i in p_rank:\n",
    "    try:\n",
    "        Peak_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Peak_rank.append('NaN')\n",
    "        \n",
    "# scraping weeks on board\n",
    "board= driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in board:\n",
    "    try:\n",
    "        Weeks_on_board.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Weeks_on_board.append('NaN')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# creating dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Song_name'] = Song_name\n",
    "df['Artist_name'] = Artist_name\n",
    "df['Last_week_rank'] = Last_week_rank\n",
    "df['Peak_rank'] = Peak_rank\n",
    "df['Weeks_on_board'] = Weeks_on_board\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f1fb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e3ecf",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e7c05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0525ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the 3 popup windows\n",
    "for _ in range(3):\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    time.sleep(1)\n",
    "    driver.close()\n",
    "driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933af2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search \n",
    "search = driver.find_element_by_xpath(\"//*[@id='qsb-keyword-sugg']\")\n",
    "search.send_keys('Data Scientist')\n",
    "\n",
    "click = driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section/div/form/div[3]/button\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7511fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on chatbot\n",
    "chat_bar = driver.find_element_by_xpath(\"//div[@class='crossIcon chatBot chatBot-ic-cross']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7df81a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>We are a leading health technology company foc...</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Health insurance</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Think-I offers a range of pharmaceutical resea...</td>\n",
       "      <td>Think i</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kochi/Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist | Fortune 500 Supermarke...</td>\n",
       "      <td></td>\n",
       "      <td>TALENT500 TECH (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist / Senior Data Scientist</td>\n",
       "      <td>EMBLAZE was founded in 2013 with the motive to...</td>\n",
       "      <td>Emblaze Solutions</td>\n",
       "      <td>Azure</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist, Presales</td>\n",
       "      <td>Moveworks is a cloud-based AI platform purpose...</td>\n",
       "      <td>Moveworks</td>\n",
       "      <td>Usage</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Leading Client</td>\n",
       "      <td>Easy Recruit</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Recommender Systems</td>\n",
       "      <td>Tickled Media started in 2009 as a digital pla...</td>\n",
       "      <td>Tickled Media</td>\n",
       "      <td>Recommender Systems</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist (Risk Analytics - Derivatives) ...</td>\n",
       "      <td>J.P. Morgan is a leader in financial services,...</td>\n",
       "      <td>JPMorgan Services India Pvt. Ltd</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>BukuWarung is a Y-Combinator backed technology...</td>\n",
       "      <td>Bukuwarung</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>TROR PRIVATE LIMITED</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Senior Data Scientist - Marketing</td>\n",
       "      <td>Tide Software</td>\n",
       "      <td>Tide Software</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>At ResMed (NYSE: RMD, ASX: RMD) we pioneer inn...</td>\n",
       "      <td>ResMed</td>\n",
       "      <td>Data management</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Co-Founder - Principal Data Scientist/Senior D...</td>\n",
       "      <td>We are an AI Health Tech Innovation Global com...</td>\n",
       "      <td>Benovymed Healthcare Private Limited</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Shell</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Machine Learning Engineer / Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Alia Premedia Services Pvt. Ltd</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                               Senior Data Scientist   \n",
       "1                                      Data Scientist   \n",
       "2   Senior Data Scientist | Fortune 500 Supermarke...   \n",
       "3         Lead Data Scientist / Senior Data Scientist   \n",
       "4                       Lead Data Scientist, Presales   \n",
       "5                               Senior Data Scientist   \n",
       "6   Lead Data Scientist - Machine Learning/ Data M...   \n",
       "7                Data Scientist - Recommender Systems   \n",
       "8   Data Scientist (Risk Analytics - Derivatives) ...   \n",
       "9                        Senior / Lead Data Scientist   \n",
       "10                                                  -   \n",
       "11                              Senior Data Scientist   \n",
       "12                                                  -   \n",
       "13                                                  -   \n",
       "14                  Senior Data Scientist - Marketing   \n",
       "15                                Lead Data Scientist   \n",
       "16  Co-Founder - Principal Data Scientist/Senior D...   \n",
       "17                                                  -   \n",
       "18                           Associate Data Scientist   \n",
       "19         Machine Learning Engineer / Data Scientist   \n",
       "\n",
       "                                          Designation  \\\n",
       "0   We are a leading health technology company foc...   \n",
       "1   Think-I offers a range of pharmaceutical resea...   \n",
       "2                                                       \n",
       "3   EMBLAZE was founded in 2013 with the motive to...   \n",
       "4   Moveworks is a cloud-based AI platform purpose...   \n",
       "5                                      Leading Client   \n",
       "6                        Wrackle Technologies Pvt Ltd   \n",
       "7   Tickled Media started in 2009 as a digital pla...   \n",
       "8   J.P. Morgan is a leader in financial services,...   \n",
       "9   BukuWarung is a Y-Combinator backed technology...   \n",
       "10                                                  -   \n",
       "11                                                      \n",
       "12                                                  -   \n",
       "13                                                  -   \n",
       "14                                      Tide Software   \n",
       "15  At ResMed (NYSE: RMD, ASX: RMD) we pioneer inn...   \n",
       "16  We are an AI Health Tech Innovation Global com...   \n",
       "17                                                  -   \n",
       "18                Shell India Markets Private Limited   \n",
       "19                                                      \n",
       "\n",
       "                                   Company     Skills they hire for  \\\n",
       "0                    Philips India Limited         Health insurance   \n",
       "1                                  Think i             Data Science   \n",
       "2   TALENT500 TECH (INDIA) PRIVATE LIMITED                 Big Data   \n",
       "3                        Emblaze Solutions                    Azure   \n",
       "4                                Moveworks                    Usage   \n",
       "5                             Easy Recruit             Data Science   \n",
       "6             Wrackle Technologies Pvt Ltd             Data Science   \n",
       "7                            Tickled Media      Recommender Systems   \n",
       "8         JPMorgan Services India Pvt. Ltd  Artificial Intelligence   \n",
       "9                               Bukuwarung             Data Science   \n",
       "10                                       -                        -   \n",
       "11                    TROR PRIVATE LIMITED             Data Science   \n",
       "12                                       -                        -   \n",
       "13                                       -                        -   \n",
       "14                           Tide Software             Data Science   \n",
       "15                                  ResMed          Data management   \n",
       "16    Benovymed Healthcare Private Limited             Data Science   \n",
       "17                                       -                        -   \n",
       "18                                   Shell             Data Science   \n",
       "19         Alia Premedia Services Pvt. Ltd                    Cloud   \n",
       "\n",
       "                  Location  \n",
       "0                  Chennai  \n",
       "1             Kochi/Cochin  \n",
       "2      Bangalore/Bengaluru  \n",
       "3                   Mumbai  \n",
       "4      Bangalore/Bengaluru  \n",
       "5      Bangalore/Bengaluru  \n",
       "6      Bangalore/Bengaluru  \n",
       "7                   Mumbai  \n",
       "8       Mumbai (All Areas)  \n",
       "9      Bangalore/Bengaluru  \n",
       "10                       -  \n",
       "11  Hyderabad/Secunderabad  \n",
       "12                       -  \n",
       "13                       -  \n",
       "14  Hyderabad/Secunderabad  \n",
       "15  Hyderabad/Secunderabad  \n",
       "16        Gurgaon/Gurugram  \n",
       "17                       -  \n",
       "18                 Chennai  \n",
       "19                  Remote  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping necessary links        \n",
    "href = []\n",
    "lnks=driver.find_elements_by_xpath(\"//*[@id='root']/div/div/section/div/article/div/div/a\")\n",
    "for lnk in lnks:\n",
    "    href.append(lnk.get_attribute('href'))\n",
    "    \n",
    "# empty list\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []\n",
    "\n",
    "\n",
    "for i in href:\n",
    "    driver.get(i)\n",
    "    driver.implicitly_wait(5)\n",
    "    # scraping the name\n",
    "    try:\n",
    "        name = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[1]/div[1]/div[1]/header/h1\")\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "    \n",
    "    # scraping the designation\n",
    "    try:\n",
    "        desig = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[3]/div[1]\")\n",
    "        Designation.append(desig.text)\n",
    "    except NoSuchElementException:\n",
    "        Designation.append('-')\n",
    "    \n",
    "    # scraping the company name\n",
    "    try:\n",
    "        comp = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[1]/div[1]/div[1]/div/a[1]\")\n",
    "        Company.append(comp.text)\n",
    "    except NoSuchElementException:\n",
    "        Company.append('-')\n",
    "    \n",
    "    # scraping the skills\n",
    "    try:\n",
    "        skill = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[2]/div[4]/div[2]/a\")\n",
    "        Skills.append(skill.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills.append('-')\n",
    "    \n",
    "    # scraping the location\n",
    "    try:\n",
    "        loc = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[3]/span/a\")\n",
    "        Location.append(loc.text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append('-')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# creating dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['Name'] = Name\n",
    "df['Designation'] = Designation\n",
    "df['Company'] = Company\n",
    "df['Skills they hire for'] = Skills\n",
    "df['Location'] = Location\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace724c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6bdfe",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dce1103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "#empity lists\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "\n",
    "# ecraping the top 100 book name\n",
    "\n",
    "name = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Book_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Book_name.append('-')\n",
    "\n",
    "# ecraping the author name\n",
    "\n",
    "a_name = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in a_name:\n",
    "    try:\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append(\"-\")\n",
    "\n",
    "# ecraping the volume sold\n",
    "\n",
    "vol_sold = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in vol_sold:\n",
    "    try:\n",
    "        Volumes_sold.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Volumes_sold.append('-')\n",
    "\n",
    "# ecraping the publisher name\n",
    "\n",
    "pub = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in pub:\n",
    "    try:\n",
    "        Publisher.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Publisher.append('-')\n",
    "\n",
    "# ecraping the genre\n",
    "\n",
    "genre = driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# creating data frame\n",
    "Books_detail = pd.DataFrame({})\n",
    "Books_detail['Book_name'] = Book_name\n",
    "Books_detail['Author_name'] = Author_name\n",
    "Books_detail['Volumes_sold'] = Volumes_sold\n",
    "Books_detail['Publisher'] = Publisher\n",
    "Books_detail['Genre'] = Genre\n",
    "Books_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feaa062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ba48e",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88deb783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,893,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>924,932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>909,761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>272,248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>232,626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>46,227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>57,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>179,061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>37,496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>210,096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  1,893,366  \n",
       "1    51 min     8.7    924,932  \n",
       "2    44 min     8.2    909,761  \n",
       "3    60 min     7.5    272,248  \n",
       "4    43 min     7.6    232,626  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     46,227  \n",
       "96   50 min     7.8     57,069  \n",
       "97   42 min     8.1    179,061  \n",
       "98   45 min     7.1     37,496  \n",
       "99  572 min     8.6    210,096  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "\n",
    "\n",
    "# scraping the name of the movies\n",
    "name = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/h3/a\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "        \n",
    "# scraping the year span\n",
    "year = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/h3/span[2]\")\n",
    "for i in year:\n",
    "    try:\n",
    "        Year_span.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year_span.append(\"-\")\n",
    "        \n",
    "# scraping the genre\n",
    "genre = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/p[1]/span[5]\")\n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "        \n",
    "# scraping run time\n",
    "time = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/p[1]/span[3]\")\n",
    "for i in time:\n",
    "    try:\n",
    "        Run_time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Run_time.append('-')\n",
    "        \n",
    "# scraping ratings\n",
    "rat = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/div[1]/div[1]/span[2]\")\n",
    "for i in rat:\n",
    "    try:\n",
    "        Ratings.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append('-')\n",
    "        \n",
    "# scraping votes\n",
    "vote = driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div/p[4]/span[2]\")\n",
    "for i in vote:\n",
    "    try:\n",
    "        Votes.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Votes.append('-')\n",
    "        \n",
    "        \n",
    "\n",
    "# creating dataframe\n",
    "movie_list = pd.DataFrame({})\n",
    "movie_list['Name'] = Name\n",
    "movie_list['Year_span'] = Year_span\n",
    "movie_list['Genre'] = Genre\n",
    "movie_list['Run_time'] = Run_time\n",
    "movie_list['Ratings'] = Ratings\n",
    "movie_list['Votes'] = Votes\n",
    "movie_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a96bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5dc520",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e4cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Chrome driver to access the link:\n",
    "driver = webdriver.Chrome(r\"C:\\Program Files (x86)\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(3)\n",
    "# click on view all\n",
    "view_all = driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "# empty lists\n",
    "Dataset_name = []\n",
    "dtype = []\n",
    "Data_type = []\n",
    "Task_dummy = []\n",
    "Task = []\n",
    "Attribute_type_dummy = []\n",
    "Attribute_type = []\n",
    "No_of_instances_dummy = []\n",
    "No_of_instances = []\n",
    "No_of_attribute_dummy = []\n",
    "No_of_attribute = []\n",
    "year_dummy = []\n",
    "Year = []\n",
    "\n",
    "\n",
    "\n",
    "# scraping the name of the dataset\n",
    "name = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td/table/tbody/tr/td/p/b/a\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Dataset_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "\n",
    "# scraping the types of dataset\n",
    "type_ = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]/p\")\n",
    "for i in type_:\n",
    "    try:\n",
    "        dtype.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        dtype.append('-')\n",
    "\n",
    "for z in dtype:\n",
    "    if z == 'Data Types':\n",
    "        continue\n",
    "    Data_type.append(z)\n",
    "\n",
    "# scraping the task of dataset\n",
    "task = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]/p\")\n",
    "for i in task:\n",
    "    try:\n",
    "        Task_dummy.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Task_dummy.append('-')\n",
    "for z in Task_dummy:\n",
    "    if z == 'Default Task':\n",
    "        continue\n",
    "    Task.append(z)\n",
    "\n",
    "# scraping the attribute type in dataset\n",
    "attribute = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p\")\n",
    "for i in attribute:\n",
    "    try:\n",
    "        Attribute_type_dummy.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type_dummy.append('-')\n",
    "for z in Attribute_type_dummy:\n",
    "    if z == 'Attribute Types':\n",
    "        continue\n",
    "    Attribute_type.append(z)\n",
    "\n",
    "# scraping the number of instances in dataset\n",
    "instances = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]/p\")\n",
    "for i in instances:\n",
    "    try:\n",
    "        No_of_instances_dummy.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances_dummy.append('-')\n",
    "for z in No_of_instances_dummy:\n",
    "    if z == '# Instances':\n",
    "        continue\n",
    "    No_of_instances.append(z)\n",
    "    \n",
    "# scraping the number of attributes in dataset    \n",
    "n_attrib = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p\")\n",
    "for i in n_attrib:\n",
    "    try:\n",
    "        No_of_attribute_dummy.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute_dummy.append('-')\n",
    "for z in No_of_attribute_dummy:\n",
    "    if z == '# Attributes':\n",
    "        continue\n",
    "    No_of_attribute.append(z)      \n",
    "    \n",
    "# scraping the years of dataset    \n",
    "year = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p\")\n",
    "for i in year:\n",
    "    try:\n",
    "        year_dummy.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        year_dummy.append('-')\n",
    "for z in year_dummy:\n",
    "    if z == 'Year':\n",
    "        continue\n",
    "    Year.append(z)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39688369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset_name      Data_type                  Task  \\\n",
       "0                             Abalone  Multivariate        Classification    \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "4                          Arrhythmia  Multivariate        Classification    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "583                                       12684              23   2020   \n",
       "584                        Real              48             321   2020   \n",
       "585                        Real             731            1068   2021   \n",
       "586                        Real             731            1068   2021   \n",
       "587                        Real             557               5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci = pd.DataFrame({})\n",
    "uci ['Dataset_name'] = Dataset_name\n",
    "uci['Data_type'] = Data_type\n",
    "uci['Task'] = Task\n",
    "uci['Attribute_type'] = Attribute_type\n",
    "uci['No_of_instances'] = No_of_instances\n",
    "uci['No_of_attribute'] = No_of_attribute\n",
    "uci['Year'] = Year\n",
    "uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0968a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259232b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
